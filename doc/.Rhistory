feature_scores <- rbind(feature_scores, feature_i)
}
print(feature_i)
}
}
feature_scores[,1:6]
feature_scores
feature_scores[is.nan(feature_scores)] <- 0
class(feature_scores)
is.nan(feature_scores)
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
feature_scores[is.nan(feature_scores)] <- 0
feature_scores
train_data
context_3gram_freq[1:10]
count_relaxed_freq <- function(ngram, ngram_table){
freq <- 0
for (i in length(ngram_table$ngram)){
n_gram <- unlist(strsplit(ngram_table$ngram[i], ' '))
if (sum(n_gram == ngram) >= 2){
freq <- freq + ngram_table$count[i]
}
}
return(freq)
}
count_freq <- function(ngram, ngram_table){
ngram_paste <- paste(ngram, collapse = " ")
if(ngram_paste %in% ngram_table$ngram){
return(ngram_table$count[ngram_table$ngram == ngram_paste])
} else{
return(0)
}
}
count_relaxed_freq(c("for", "majors", "in"),context_3gram_freq)
count_freq(c("for", "majors", "in"),context_3gram_freq)
count_relaxed_freq <- function(ngram, ngram_table){
freq <- 0
for (i in length(ngram_table$ngram)){
n_gram <- unlist(strsplit(ngram_table$ngram[i], ' '))
print(n_gram)
if (sum(n_gram == ngram) >= 2){
freq <- freq + ngram_table$count[i]
}
}
return(freq)
}
count_relaxed_freq(c("for", "majors", "in"),context_3gram_freq)
context_3gram_freq$ngram
count_relaxed_freq <- function(ngram, ngram_table){
freq <- 0
for (i in 1:length(ngram_table$ngram)){
n_gram <- unlist(strsplit(ngram_table$ngram[i], ' '))
print(n_gram)
if (sum(n_gram == ngram) >= 2){
freq <- freq + ngram_table$count[i]
}
}
return(freq)
}
count_relaxed_freq(c("for", "majors", "in"),context_3gram_freq)
length(context_3gram_freq)
length(context_3gram_freq$ngram)
context_3gram_freq$ngram == c('member','plus','an')
context_3gram_freq$ngram
count_relaxed_freq(c("for", "majors", "in"),context_3gram_freq)
count_relaxed_freq <- function(ngram, ngram_table){
freq <- 0
for (i in 1:length(ngram_table$ngram)){
n_gram <- unlist(strsplit(ngram_table$ngram[i], ' '))
if (sum(n_gram == ngram) >= 2){
freq <- freq + ngram_table$count[i]
}
}
return(freq)
}
count_relaxed_freq(c("for", "majors", "in"),context_3gram_freq)
source('../lib/score_components.R')
cnt <- 0
for (i in 1:nrow(train_data)){
print(i)
candidates <- unlist(levenshtein.neighbors(as.character(train_data$c)[i], all_words)[1:thres])
if (length(candidates)>0){
print(candidates)
cnt <- cnt + 1
feature_i <- score_features(wc=candidates, we=as.character(train_data$c)[i], thres=2, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(train_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label=as.numeric(candidates == as.character(train_data$right_word)[i])
if (cnt==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
length(ground_truth_list)
ground_truth_txt <- readLines("../output/train_truth.txt", warn=FALSE)
ground_truth_list_vec <- lapply(ground_truth_txt, stringsplit_1st)
ground_truth_list <- unlist(ground_truth_list_vec)
train_data <- read.csv('../output/Detection_list.csv')
length(ground_truth_list)
train_data
ground_truth_txt <- readLines("../output/train_truth.txt", warn=FALSE)
ground_truth_list_vec <- lapply(ground_truth_txt, stringsplit_1st)
ground_truth_list <- unlist(ground_truth_list_vec)
train_data <- read.csv('../output/Detection_list.csv')
train_data
train_data[1,]
# load data
ground_truth_txt <- readLines("../output/train_truth.txt", warn=FALSE)
ground_truth_list_vec <- lapply(ground_truth_txt, stringsplit_1st)
ground_truth_list <- unlist(ground_truth_list_vec)
train_data <- read.csv('../output/Detection_list.csv')
# Use training ground truth to create n-gram context
n_gram <- 3
context_ground_truth <- list()
for (i in 1:(length(ground_truth_list)-(n_gram-1))){
context_name <- paste(ground_truth_list[(i):(i+n_gram-1)], collapse = " ")
context_ground_truth[[i]] <- context_name
}
context_3gram_freq <- list(ngram = unlist(unique(context_ground_truth)),
count = tabulate(match(context_ground_truth, unique(context_ground_truth))))
# set Levenshtein distance threshold
thres <- 1
all_words <- unique(c(english.words, tolower(ground_truth_list)))
# create the training features and labels
cnt <- 0
for (i in 1:nrow(train_data)){
print(i)
candidates <- unlist(levenshtein.neighbors(as.character(train_data$c)[i], all_words)[1:thres])
if (length(candidates)>0){
cnt <- cnt + 1
feature_i <- score_features(wc=candidates, we=as.character(train_data$c)[i], thres=2, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(train_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label=as.numeric(candidates == as.character(train_data$Truth)[i])
if (cnt==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
cnt <- 0
for (i in 1:nrow(train_data)){
print(i)
candidates <- unlist(levenshtein.neighbors(as.character(train_data$c)[i], all_words)[1:thres])
print(candidates)
if (length(candidates)>0){
cnt <- cnt + 1
feature_i <- score_features(wc=candidates, we=as.character(train_data$c)[i], thres=2, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(train_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label=as.numeric(candidates == as.character(train_data$Truth)[i])
if (cnt==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
source('../lib/score_components.R')
all_words <- unique(c(english.words, tolower(ground_truth_list)))
# create the training features and labels
cnt <- 0
for (i in 1:nrow(train_data)){
print(i)
candidates <- unlist(levenshtein.neighbors(as.character(train_data$c)[i], all_words)[1:thres])
print(candidates)
if (length(candidates)>0){
cnt <- cnt + 1
feature_i <- score_features(wc=candidates, we=as.character(train_data$c)[i], thres=2, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(train_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label=as.numeric(candidates == as.character(train_data$Truth)[i])
if (cnt==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
5%10
5%%10
nrow(train_data)
# create the training features and labels
cnt <- 0
for (i in 1:nrow(train_data)){
if (i %% 1000 == 1){
print(i)
}
candidates <- unlist(levenshtein.neighbors(as.character(train_data$c)[i], all_words)[1:thres])
if (length(candidates)>0){
cnt <- cnt + 1
feature_i <- score_features(wc=candidates, we=as.character(train_data$c)[i], thres=2, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(train_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label=as.numeric(candidates == as.character(train_data$Truth)[i])
if (cnt==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
feature_scores
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
feature_scores[is.nan(feature_scores)] <- 0
save(feature_scores, file="../output/train_correction.RData")
save(feature_scores, file="../output/train_correction.RData")
feature_scores
feature_scores$label
sum(feature_scores$label)
train_data$Truth
as.character(train_data$Truth)
as.character(train_data$Truth)[1]
train_data
train_data$Truth
head(train_data)
train_data$Truth
train_data$tess == traian_data$Truth
train_data$tess == train_data$Truth
label
head(feature_scores)
feature_scores$context_pop
train_data <- read.csv('../output/train_error.csv')
# create the training features and labels
cnt <- 0
for (i in 1:nrow(train_data)){
if (i %% 1000 == 1){
print(i)
}
candidates <- unlist(levenshtein.neighbors(as.character(train_data$c)[i], all_words)[1:thres])
if (length(candidates)>0){
cnt <- cnt + 1
#    feature_i <- score_features(wc=candidates, we=as.character(train_data$c)[i], thres=1, lexicon=ground_truth_list,
#                             context_we=as.character(data.frame(lapply(train_data[i,2:6], as.character), stringsAsFactors=FALSE)),
#                             context_3grams_freq=context_3gram_freq)
#    feature_i$label=as.numeric(candidates == as.character(train_data$Truth)[i])
#    if (cnt==1){
#      feature_scores <- feature_i
#    } else{
#      feature_scores <- rbind(feature_scores, feature_i)
#    }
if (cnt==1){
labels <- as.numeric(candidates == as.character(train_data$Truth)[i])
} else{
labels <- c(labels, as.numeric(candidates == as.character(train_data$Truth)[i]))
}
}
}
labels
sum(labels)
feature_scores$label <- labels
feature_scores$label
nrow(feature_scores)
head(feature_scores)
save(feature_scores, file="../output/train_correction.RData")
feat_train <- feature_scores[,1:5]
label_train <- feat_train$label
feat_train
label_train
label_train <- feature_scores$label
label_train
source("../lib/xgb_train.R")
source("../lib/xgb_test.R")
tm_train_xgb=NA
par_best_xgb <- 4
tm_train_xgb <- system.time(fit_train_xgb <- xgb_train(feat_train, label_train, par_best_xgb))
par_best_xgb <- list(depth=4)
tm_train_xgb <- system.time(fit_train_xgb <- xgb_train(feat_train, label_train, par_best_xgb))
data.matrix(feat_train)
data.matrix(feat_train)[1:5,]
feat_train[1:5,]
data.matrix(feature_scores$label)
feat_train <- data.matrix(feature_scores[,1:5])
label_train <- data.matrix(feature_scores$label)
tm_train_xgb=NA
par_best_xgb <- list(depth=4)
tm_train_xgb <- system.time(fit_train_xgb <- xgb_train(feat_train, label_train, par_best_xgb))
source("../lib/xgb_train.R")
source("../lib/xgb_test.R")
tm_train_xgb=NA
par_best_xgb <- list(depth=4)
tm_train_xgb <- system.time(fit_train_xgb <- xgb_train(feat_train, label_train, par_best_xgb))
source("../lib/xgb_train.R")
source("../lib/xgb_test.R")
tm_train_xgb=NA
par_best_xgb <- list(depth=4)
tm_train_xgb <- system.time(fit_train_xgb <- xgb_train(feat_train, label_train, par_best_xgb))
save(fit_train_xgb_8, file="../output/fit_train_xgb.RData")
save(fit_train_xgb, file="../output/fit_train_xgb.RData")
?xgb.importance
colnames(feature_scores)
colnames(feature_scores)[1:5]
importance <- xgb.importance(feature_names = colnames(feature_scores)[1:5], model = fit_train_xgb)
print(importance)
feature_scores
train_data
head(train_data)
head(feature_scores)
train_data <- read.csv('../output/test_error.csv')
test_data <- read.csv('../output/test_error.csv')
test_data
head(test_data)
train_data <- read.csv('../output/train_error.csv')
nrow(test_data)
test_data[1,'tess']
as.character(test_data[1,'tess'])
test_data$asd <- as.character(test_data[1,'tess'])
test_data
test_data$asd
test_data <- test_data[1:5000,]
thres1 <- 1
# create the test features and labels
cnt1 <- 0
for (i in 1:nrow(test_data)){
if (i %% 1000 == 1){
print(i)
}
candidates <- unlist(levenshtein.neighbors(as.character(test_data$c)[i], all_words)[1:thres1])
if (length(candidates)>0){
cnt1 <- cnt1 + 1
feature_i <- score_features(wc=candidates, we=as.character(test_data$c)[i], thres=1, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(test_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label <- as.numeric(candidates == as.character(test_data$Truth)[i])
feature_i$tess <- as.character(test_data[i,'tess'])
feature_i$cand <- candidates
feature_i$truth <- as.character(test_data[i,'Truth'])
print(feature_i)
if (cnt==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
head(test_data)
nrow(test_data)
head(train_data)
train_data
train_data$Truth
cnt1 <- 0
for (i in 1:nrow(test_data)){
if (i %% 1000 == 1){
print(i)
}
candidates <- unlist(levenshtein.neighbors(as.character(test_data$c)[i], all_words)[1:thres1])
if (length(candidates)>0){
cnt1 <- cnt1 + 1
feature_i <- score_features(wc=candidates, we=as.character(test_data$c)[i], thres=1, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(test_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label <- as.numeric(candidates == as.character(test_data$Truth)[i])
feature_i$tess <- as.character(test_data[i,'tess'])
feature_i$cand <- candidates
feature_i$truth <- as.character(test_data[i,'Truth'])
print(feature_i)
if (cnt==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
# create the test features and labels
cnt1 <- 0
for (i in 1:nrow(test_data)){
if (i %% 1000 == 1){
print(i)
}
candidates <- unlist(levenshtein.neighbors(as.character(test_data$c)[i], all_words)[1:thres1])
if (length(candidates)>0){
cnt1 <- cnt1 + 1
feature_i <- score_features(wc=candidates, we=as.character(test_data$c)[i], thres=1, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(test_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label <- as.numeric(candidates == as.character(test_data$Truth)[i])
feature_i$tess <- as.character(test_data[i,'tess'])
feature_i$cand <- candidates
feature_i$truth <- as.character(test_data[i,'Truth'])
print(feature_i)
if (cn1==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
thres1 <- 1
# create the test features and labels
cnt1 <- 0
for (i in 1:nrow(test_data)){
if (i %% 1000 == 1){
print(i)
}
candidates <- unlist(levenshtein.neighbors(as.character(test_data$c)[i], all_words)[1:thres1])
if (length(candidates)>0){
cnt1 <- cnt1 + 1
feature_i <- score_features(wc=candidates, we=as.character(test_data$c)[i], thres=1, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(test_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label <- as.numeric(candidates == as.character(test_data$Truth)[i])
feature_i$tess <- as.character(test_data[i,'tess'])
feature_i$cand <- candidates
feature_i$truth <- as.character(test_data[i,'Truth'])
if (cnt1==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
test_data <- read.csv('../output/test_error.csv')
test_data <- test_data[1:5000,]
thres1 <- 1
# create the test features and labels
cnt1 <- 0
for (i in 1:nrow(test_data)){
if (i %% 1000 == 1){
print(i)
}
candidates <- unlist(levenshtein.neighbors(as.character(test_data$c)[i], all_words)[1:thres1])
if (length(candidates)>0){
cnt1 <- cnt1 + 1
feature_i <- score_features(wc=candidates, we=as.character(test_data$c)[i], thres=1, lexicon=ground_truth_list,
context_we=as.character(data.frame(lapply(test_data[i,2:6], as.character), stringsAsFactors=FALSE)),
context_3grams_freq=context_3gram_freq)
feature_i$label <- as.numeric(candidates == as.character(test_data$Truth)[i])
feature_i$tess <- as.character(test_data[i,'tess'])
feature_i$cand <- candidates
feature_i$truth <- as.character(test_data[i,'Truth'])
if (cnt1==1){
feature_scores <- feature_i
} else{
feature_scores <- rbind(feature_scores, feature_i)
}
}
}
feature_scores
save(feature_scores, file="../output/test_correction.RData")
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
feature_scores[is.nan(feature_scores)] <- 0
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
feature_scores_test[is.nan(feature_scores_test)] <- 0
feat_test <- data.matrix(feature_scores[,1:5])
label_test <- data.matrix(feature_scores$label)
head(feature_scores)
feature_scores$label
predicted_score <- xgb_test(fit_train_xgb, feat_test)
source("../lib/xgb_test.R")
predicted_score <- xgb_test(fit_train_xgb, feat_test)
source("../lib/xgb_test.R")
predicted_score <- xgb_test(fit_train_xgb, feat_test)
predicted_score
feature_scores[1:20,]
unique(feature_scores$tess)
feature_scores_test <- feature_scores
max(c(1,1,3))
which.max(c(1,1,3))
which.max(c(1,3,3))
cnt2 <- 0
for (each in unique(feature_scores_test$tess)){
cnt2 <- cnt2 + 1
each_index <- which(feature_scores_test$tess == each)
test_each <- feature_scores_test[each_index,]
max_index <- which.max(predicted_score[each_index])
correction_each <- test_each[max_index, 'cand']
if (cnt2==1){
correction <- correction_each
} else{
correction <- c(correction, correction_each)
}
}
correction
correction == feature_scores_test$truth
head(feature_scores_test)
correction
head(correction)
correction == unique(feature_scores_test$truth)
unique(feature_scores_test$truth)
length(correction)
length(predicted_score)
length(unique(feature_scores_test$truth))
predicted_score <- xgb_test(fit_train_xgb, feat_test)
cnt2 <- 0
for (each in unique(feature_scores_test$tess)){
cnt2 <- cnt2 + 1
each_index <- which(feature_scores_test$tess == each)
test_each <- feature_scores_test[each_index,]
max_index <- which.max(predicted_score[each_index])
correction_each <- test_each[max_index, 'cand']
truth_each <- test_each[max_index, 'truth']
if (cnt2==1){
correction <- correction_each
test_truth <- truth_each
} else{
correction <- c(correction, correction_each)
test_truth <- c(test_truth, truth_each)
}
}
correction == test_truth
sum(correction == test_truth)/length(correction)
sum(correction == test_truth)/5000
correction
truth
test_data
