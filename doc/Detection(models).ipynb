{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#Random forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Xgboost\n",
    "from xgboost import XGBClassifier  #pip install xgboost\n",
    "#svm\n",
    "from sklearn import svm\n",
    "#gbm\n",
    "from sklearn import ensemble\n",
    "#logistics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from tabulate import tabulate\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "df=pd.DataFrame.from_csv(\"D3_features.csv\")#this file should be putted in the current working directory\n",
    "labels = np.array(df['V25'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df.drop('V25', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##traning##\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "# Train the model on training data\n",
    "rf_model = rf.fit(train_features, train_labels)\n",
    "rf.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##testing##\n",
    "# Use the forest's predict method on the test data\n",
    "predictions_rf = rf.predict(test_features)\n",
    "##evaluation##\n",
    "rf.score(test_features,test_labels)\n",
    "#confusion matrix\n",
    "print(confusion_matrix(test_labels,predictions_rf))  \n",
    "print(classification_report(test_labels,predictions_rf))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##training##\n",
    "t10=time.time() #Track time\n",
    "clf = svm.SVC(C=0.8, kernel='rbf', gamma=20, decision_function_shape='ovr')\n",
    "clf.fit(train_features, train_labels)\n",
    "t11=time.time()\n",
    "print(\"Time:\", t10,t11)\n",
    "print(\"Train:\",clf.score(train_features, train_labels)) # train score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##testing##\n",
    "predictions_svm = clf.predict(test_features)\n",
    "##evaluation##\n",
    "clf.score(test_features,test_labels) \n",
    "##confusion matrix##\n",
    "print(confusion_matrix(test_labels,predictions_svm))  \n",
    "print(classification_report(test_labels,predictions_svm))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##training##\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gbm = ensemble.GradientBoostingRegressor(**params)\n",
    "gbm.fit(train_features, train_labels)\n",
    "gbm.score(train_features, train_labels)  # train score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###testing##\n",
    "predictions_gbm = gbm.predict(test_features)\n",
    "##evaluation##\n",
    "errors_gbm = abs(test_labels-predictions_gbm)\n",
    "gbm.score(test_features,test_labels)\n",
    "##confusion matrix##\n",
    "predictions_gbm1=[]\n",
    "for i in range(len(predictions_gbm)):\n",
    "    if predictions_gbm[i]>0.5:\n",
    "        predictions_gbm1.append(1)\n",
    "    else:\n",
    "        predictions_gbm1.append(0)\n",
    "print(confusion_matrix(test_labels,predictions_gbm1))  \n",
    "print(classification_report(test_labels,predictions_gbm1))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##training##\n",
    "xg = XGBClassifier()\n",
    "xg_model=xg.fit(train_features, train_labels)\n",
    "xg.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##testing##\n",
    "predictions_xg = xg.predict(test_features)\n",
    "##evaluation##\n",
    "errors_xg = abs(test_labels-predictions_xg)\n",
    "xg.score(test_features,test_labels)\n",
    "#confusion matrix##\n",
    "print(confusion_matrix(test_labels,predictions_xg))  \n",
    "print(classification_report(test_labels,predictions_xg))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##features selection##\n",
    "#The code for feature selection is similar for Random Forest and Xgboost\n",
    "features= df.drop('V25', axis = 1)\n",
    "features.columns\n",
    "headers = [\"name\", \"score\"]\n",
    "values2 = sorted(zip(features.columns, xg_model.feature_importances_), key=lambda x: x[1] * -1)\n",
    "print(tabulate(values2, headers, tablefmt=\"plain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##train##\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_features, train_labels)\n",
    "lr.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##test##\n",
    "predictions_lr=lr.predict(test_features)\n",
    "##evaluation##\n",
    "error_lr=abs(test_labels-predictions_lr)\n",
    "lr.score(test_features, test_labels)\n",
    "##confusion matrix##\n",
    "print(confusion_matrix(test_labels,predictions_lr))  \n",
    "print(classification_report(test_labels,predictions_lr))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
